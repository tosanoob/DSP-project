{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sn\n",
    "from sklearn import metrics\n",
    "import time\n",
    "# Các bước thực hiện\n",
    "# 1. Đọc file tests training & label\n",
    "# 2. Chia 3, lấy phần giữa (phần ổn định)\n",
    "# 3. Phân khung 30ms, dịch khung 20ms, khung chữ nhật\n",
    "# 4. Tính MFCC trên từng khung => trung bình MFCC trên tất cả các khung => đặc trưng của 1 audio\n",
    "# 5. Tính trung bình đặc trưng của 21 audio của mỗi nguyên âm => đặc trưng nguyên âm\n",
    "#### Lưu lại các vector hệ số\n",
    "# 6. Đọc file input test\n",
    "# 7. Chia 3 lấy phần giữa\n",
    "# 8. Phân khung 30ms, dịch khung 20ms, khung chữ nhật\n",
    "\n",
    "frame_length = 0.03\n",
    "frame_hop = 0.02\n",
    "K = 5  # 2 3 4 5\n",
    "\n",
    "# functions ---------------------\n",
    "def get_stable_audio(filepath):  # trả về phần ổn định ở chính giữa của audio\n",
    "    audio, sr = librosa.load(filepath, sr=None)\n",
    "    div_part = len(audio) // 3\n",
    "    center_part = audio[div_part : 2 * div_part]\n",
    "    center_part = center_part/(max(abs(center_part)))\n",
    "    return center_part, sr\n",
    "\n",
    "\n",
    "def windowing(\n",
    "    audio, sr, frame_length=0.03, frame_hop=0.025\n",
    "):  # windowing với length, hop\n",
    "    frame_size = int(frame_length * sr)\n",
    "    hop_size = int(frame_hop * sr)\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(0, len(audio), hop_size):\n",
    "        if i + frame_size < len(audio):\n",
    "            frames.append(audio[i : i + frame_size])\n",
    "    return frames\n",
    "\n",
    "\n",
    "def mfcc(frame, N, sr):  # tính N đặc trưng MFCC trên frame, viết gọn của librosa\n",
    "    return librosa.feature.mfcc(y=frame, sr=sr, n_mfcc=N)\n",
    "\n",
    "\n",
    "# Đọc input\n",
    "test_path = \".\\\\trimmed_signals\\\\HuanLuyen-16k\"\n",
    "\n",
    "input = []\n",
    "N_MFCC = 13\n",
    "for file in sorted(os.listdir(test_path)):\n",
    "    # print(os.path.join(path,file))\n",
    "    sub_path = os.path.join(test_path, file)\n",
    "    for sub_file in sorted(os.listdir(sub_path)):\n",
    "        exact_test_path = os.path.join(sub_path, sub_file)\n",
    "        label = sub_file.split(\".\")[0]\n",
    "\n",
    "        audio, sr = get_stable_audio(exact_test_path)\n",
    "        frames = windowing(audio, sr, frame_length, frame_hop)\n",
    "\n",
    "        # Tính trung bình trước rồi gom nhóm\n",
    "        MFCCs = []\n",
    "        for frame in frames:\n",
    "            MFCCs.append(mfcc(frame,N_MFCC,sr))\n",
    "        feature = np.average(MFCCs,axis=0)\n",
    "        feature = feature/max(abs(feature))\n",
    "\n",
    "        input.append([feature, label])\n",
    "\n",
    "        # Gom nhóm không cần tính trung bình theo từng audio\n",
    "        # for frame in frames:\n",
    "        #     vector = mfcc(frame, N_MFCC, sr)\n",
    "        #     vector = vector/max(abs(vector))\n",
    "        #     input.append([vector, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by labels\n",
    "features = {'a': [], 'e':[], 'i':[], 'o':[], 'u':[]}\n",
    "for j in input:\n",
    "    features[j[1]].append(j[0])\n",
    "# print(features['a'])\n",
    "# print(len(features['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_features = {\n",
    "    \"a\": np.average(features[\"a\"], axis=0),\n",
    "    \"e\": np.average(features[\"e\"], axis=0),\n",
    "    \"i\": np.average(features[\"i\"], axis=0),\n",
    "    \"o\": np.average(features[\"o\"], axis=0),\n",
    "    \"u\": np.average(features[\"u\"], axis=0),\n",
    "}\n",
    "# print(average_features['a'])\n",
    "rows = []\n",
    "for key, f in average_features.items():\n",
    "    rows.append([key, f.reshape((N_MFCC,))])\n",
    "plt.title(\"Vector trung bình đặc trưng MFCC của 5 nguyên âm\")\n",
    "plt.plot(average_features[\"a\"])\n",
    "plt.plot(average_features[\"e\"])\n",
    "plt.plot(average_features[\"i\"])\n",
    "plt.plot(average_features[\"o\"])\n",
    "plt.plot(average_features[\"u\"])\n",
    "plt.legend([\"a\", \"e\", \"i\", \"o\", \"u\"])\n",
    "# plt.savefig(\"MFCC_Features_Vector.png\")\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"average_features_MFCC_13.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cài đặt Kmean lên tập features của từng nguyên âm, lấy tập centroids làm tập đặc trưng cho nguyên âm đó\n",
    "\n",
    "#chọn ngẫu nhiên K hàng trong X làm tâm\n",
    "def init_K(X, K):\n",
    "    return X[np.random.choice(X.shape[0], K, replace=False)]\n",
    "\n",
    "#duyệt tất cả các record và label tâm\n",
    "def clustering(X, centroids):\n",
    "    N = X.shape[0]\n",
    "    label = np.zeros((1,N))\n",
    "    for i in range (N):\n",
    "        xi = X[i,:]\n",
    "        min = np.linalg.norm(xi - centroids[0])\n",
    "        for index, c in enumerate(centroids):\n",
    "            if np.linalg.norm(xi - c) < min:\n",
    "                min = np.linalg.norm(xi - c)\n",
    "                label[0,i] = index\n",
    "    return label\n",
    "\n",
    "def cluster_of_same_label(index, label, X):\n",
    "    selected = []\n",
    "    for i in range(label.shape[1]):\n",
    "        if label[0,i] == index:\n",
    "            selected.append(X[i])\n",
    "    return np.array(selected)\n",
    "\n",
    "def isEqual(last_label, label):\n",
    "    for i in range (label.shape[1]):\n",
    "        if last_label[0,i] != label[0,i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def K_means(X, K, loop = 20):\n",
    "    count = 0\n",
    "    centroids = init_K(X,K)\n",
    "    last_label = np.zeros((1,X.shape[0]))\n",
    "    while (count < loop):\n",
    "        label = clustering(X, centroids)\n",
    "        #kiểm tra, nếu tập label không đổi => thoát\n",
    "        if isEqual(last_label, label):\n",
    "            return centroids, label\n",
    "        new_centroids = np.zeros(centroids.shape)\n",
    "        for index in range (centroids.shape[0]):\n",
    "            new_centroids[index] = np.mean(cluster_of_same_label(index,label,X), axis = 0)\n",
    "        centroids = new_centroids.copy()\n",
    "        last_label = label\n",
    "        count+=1\n",
    "    return centroids, label\n",
    "\n",
    "\n",
    "dim = N_MFCC\n",
    "Kmeans_features = {\n",
    "    'a': K_means(np.array(features['a']),K)[0], \n",
    "    'e': K_means(np.array(features['e']),K)[0],\n",
    "    'i': K_means(np.array(features['i']),K)[0], \n",
    "    'o': K_means(np.array(features['o']),K)[0], \n",
    "    'u': K_means(np.array(features['u']),K)[0]\n",
    "    }\n",
    "# print(Kmeans_features['a'])\n",
    "# print(Kmeans_features['a'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#đọc dữ liệu kiểm thử\n",
    "test_path = \".\\\\trimmed_signals\\\\KiemThu-16k\"\n",
    "\n",
    "tests = []\n",
    "\n",
    "for file in sorted(os.listdir(test_path)):\n",
    "    # print(os.path.join(path,file))\n",
    "        sub_path = os.path.join(test_path,file)\n",
    "        for sub_file in sorted(os.listdir(sub_path)):\n",
    "            exact_test_path = os.path.join(sub_path,sub_file)\n",
    "            audio, sr = get_stable_audio(exact_test_path)\n",
    "            label = sub_file.split(\".\")[0]\n",
    "            frames = windowing(audio, sr, frame_length, frame_hop)\n",
    "            MFCCs = []\n",
    "            for frame in frames:\n",
    "                MFCCs.append(mfcc(frame,N_MFCC,sr))\n",
    "            feature = np.average(MFCCs,axis=0)\n",
    "            feature = feature/max(abs(feature))\n",
    "            tests.append([feature,label]) # label này sẽ được sử dụng để kiểm tra kết quả nhận dạng\n",
    "\n",
    "# tests = np.array(tests)\n",
    "# print(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(test_vectors, features):\n",
    "    label_result = \"\"\n",
    "    min_dist = 1e6\n",
    "    for key, feature_set in features.items():\n",
    "        for f in feature_set:\n",
    "            dist = np.linalg.norm(test_vectors - f)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                label_result = key\n",
    "    return label_result\n",
    "\n",
    "\n",
    "count = 0\n",
    "keys = {\"a\": 0, \"e\": 1, \"i\": 2, \"o\": 3, \"u\": 4}\n",
    "table = np.zeros((5, 5))\n",
    "startTime = time.time()\n",
    "for test in tests:\n",
    "    label_result = classify(test[0], Kmeans_features)\n",
    "    if label_result == test[1]:\n",
    "        count += 1\n",
    "    table[keys[label_result], keys[test[1]]] += 1\n",
    "    # print(\"Label: \" + str(test[1]) + \", classified label: \" + str(label_result))\n",
    "endTime = time.time()\n",
    "print(\"Thời gian nhận dạng\", (endTime - startTime), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "Data = np.array([[K, frame_length, frame_hop, count, str(count/105*100) + \"%\"]])\n",
    "Data = np.array(Data)\n",
    "Data = Data.reshape(1, 5)\n",
    "print(Data.shape)\n",
    "# dfData = pd.DataFrame(Data, columns=[\"K\", \"frame_length\", \"frame_hop\", \"Count\", \"Percentage\"], index=None)\n",
    "dfData = pd.DataFrame(Data,columns=None ,index=None)\n",
    "# dfData.to_csv(\"Test.csv\", mode=\"a\", index=False, header=False)\n",
    "print(dfData)\n",
    "# hiển thị bảng đúng sai\n",
    "# từng hàng là label do chương trình nhận dạng\n",
    "# từng cột là label đúng của dữ liệu\n",
    "df_cm = pd.DataFrame(np.transpose(table), index=[i for i in \"AEIOU\"], columns=[i for i in \"AEIOU\"])\n",
    "sn.set(font_scale=1)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cbar=False)\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"test\")\n",
    "# plt.savefig(\"ConfusionMatrix_K =\" + str(K) + \".jpg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
